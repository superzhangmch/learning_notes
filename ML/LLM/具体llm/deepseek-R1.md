单从paper看：

对于采用用的 model $\pi_{old}$:

| 策略 | PPO | GRPO（其论文实现） |
|-------|-----|----------------------|
| π_old 更新频率 | 每隔 N 步 | ✅ 每步都同步 π_θ |
| 采样策略 | 用 π_old 采样 | ✅ 也用 π_old，但它刚同步来 |
| 是否 off-policy | 是（延迟一点） | 几乎 on-policy（同步） |
| 理由 | 保稳定性 | 简化架构，不用 critic，靠 group reward 做稳定控制 |
 
