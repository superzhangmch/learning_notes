# 《MEDUSA: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads》 2024.01 https://arxiv.org/pdf/2401.10774

medusa 不同于基于 draft model 的 speculative decoding：它是在原生 LLM 上做一些改造，使得 target LLM 自身就能给出 draft。

<img width="1274" height="954" alt="image" src="https://github.com/user-attachments/assets/85f584ee-33da-4b4e-a21d-dbf6323d6120" />

<img width="1218" height="942" alt="image" src="https://github.com/user-attachments/assets/ca660ddd-bbad-4faa-9212-bd4cb1327fa9" />
