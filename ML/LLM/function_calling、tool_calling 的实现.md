å¤§ä½“è¯´ï¼Œæ¯æ¬¡è¯·æ±‚LLMçš„æ—¶å€™ï¼Œè¦æŠŠè‡ªå·±æœ‰çš„ tool ä¿¡æ¯ï¼ˆtool å«ä»€ä¹ˆï¼Œå¹²ä»€ä¹ˆçš„ï¼Œæœ‰ä»€ä¹ˆå‚æ•°ï¼šä»€ä¹ˆåå­—ï¼Œä»€ä¹ˆç±»å‹ï¼Œä»€ä¹ˆå«ä¹‰ï¼‰ä»¥ json æ ¼å¼ä¼ ç»™ LLMï¼ŒLLM è‡ªä¸»åˆ¤æ–­ã€‚

å¦‚æœå‘ç°éœ€è¦è°ƒç”¨ toolï¼Œåˆ™ä¸‹ä¸€æ­¥ç›´æ¥è¿”å›è¦è°ƒç”¨å“ªä¸ª toolï¼ŒåŒæ—¶ä¼šæŠŠå‚æ•°å¡«å……ï¼Œè¿™æ ·å®¢æˆ·ç«¯æŠŠè¿™ä¸ªä¿¡æ¯æå–å‡ºæ¥åå°±å¯ä»¥ç›´æ¥è°ƒç”¨è‡ªå·±çš„å·¥å…·äº†ã€‚è°ƒç”¨ç»“æŸåï¼ŒæŠŠç»“æœç»™åˆ° LLMï¼Œ LLM å°±å¯ä»¥è¿”å›æœ‰ tool å¸®åŠ©ä¸‹çš„ç»“æœäº†ã€‚

ä¹Ÿå°±æ˜¯åˆ†è¿™ä¹ˆå‡ æ­¥ï¼ˆä¸¤æ¬¡ LLM äº¤äº’ï¼‰ï¼š
- ç”¨æˆ·å‘èµ·å¸¦ tool æè¿°çš„è¯·æ±‚
- LLM è¿”å› tool æ‰ç”¨çš„ json
- ç”¨æˆ·è°ƒç”¨ toolï¼Œå¹¶å†æ¬¡å‘ LLM å‘èµ·å¸¦ tool_result çš„è¯·æ±‚
- LLM è¿”å›æœ€ç»ˆç»“æœ

è±†åŒ…çš„ coze.cn ä¸Šï¼Œå¥½å¤šæ“ä½œå°±æ˜¯ç›´æ¥ç”¨çš„ tool call / function call æ¥å®ç°çš„é¢ã€‚

---

éå¸¸è¯¦ç»†çš„å®ç°ï¼Œä¹Ÿå°±æ˜¯ chatMLï¼Œå‘ç°ä¸€ä¸ª qianwen 2.5 çš„

### qianwen-2.5 çš„ chatML

https://huggingface.co/peakji/qwen2.5-72b-instruct-trim/blob/main/tokenizer_config.json

```
{%- if tools %}
    {{- '<|im_start|>system
' }}
    {%- if messages[0]['role'] == 'system' %}
        {{- messages[0]['content'] }}
    {%- else %}
        {{- 'You are a helpful assistant.' }}
    {%- endif %}
    {{- "

# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>" }}
    {%- for tool in tools %}
        {{- "
" }}
        {{- tool | tojson }}
    {%- endfor %}
    {{- "
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{\"name\": <function-name>, \"arguments\": <args-json-object>}
</tool_call><|im_end|>
" }}
{%- else %}
    {%- if messages[0]['role'] == 'system' %}
        {{- '<|im_start|>system
' + messages[0]['content'] + '<|im_end|>
' }}
    {%- else %}
        {{- '<|im_start|>system
You are a helpful assistant.<|im_end|>
' }}
    {%- endif %}
{%- endif %}
{%- for message in messages %}
    {%- if (message.role == "user") or (message.role == "system" and not loop.first) or (message.role == "assistant" and not message.tool_calls) %}
        {{- '<|im_start|>' + message.role + '
' + message.content + '<|im_end|>' + '
' }}
    {%- elif message.role == "assistant" %}
        {{- '<|im_start|>' + message.role }}
        {%- if message.content %}
            {{- '
' + message.content }}
        {%- endif %}
        {%- for tool_call in message.tool_calls %}
            {%- if tool_call.function is defined %}
                {%- set tool_call = tool_call.function %}
            {%- endif %}
            {{- '
<tool_call>
{"name": "' }}
            {{- tool_call.name }}
            {{- '", "arguments": ' }}
            {{- tool_call.arguments | tojson }}
            {{- '}
</tool_call>' }}
        {%- endfor %}
        {{- '<|im_end|>
' }}
    {%- elif message.role == "tool" %}
        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != "tool") %}
            {{- '<|im_start|>user' }}
        {%- endif %}
        {{- '
<tool_response>
' }}
        {{- message.content }}
        {{- '
</tool_response>' }}
        {%- if loop.last or (messages[loop.index0 + 1].role != "tool") %}
            {{- '<|im_end|>
' }}
        {%- endif %}
    {%- endif %}
{%- endfor %}
{%- if add_generation_prompt %}
    {{- '<|im_start|>assistant
' }}
{%- endif %}
```

ä¸€ä¸ªå…·ä½“å®ä¾‹ï¼š
```
<|im_start|>system
You are a helpful assistant.

# Tools
You may call one or more functions to assist with the user query.
You are provided with function signatures within <tools></tools> XML tags:
<tools>
{"name": "get_weather", "description": "Get current weather for a city", "parameters": {"type": "object", "properties": {"city": {"type": "string"}, "date": {"type": "string"}}}}
</tools>
For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": ..., "arguments": {...}}
</tool_call>
<|im_end|>
```

-----

å…¶ä»–å®ä¾‹ï¼š

### **GPT-4ï¼š**

### **å½“ LLM åˆ¤æ–­åº”è¯¥è°ƒç”¨æŸä¸ª toolï¼Œå®ƒä¼šç›´æ¥è¾“å‡ºç¬¦åˆæŒ‡å®šæ ¼å¼çš„ JSON è°ƒç”¨ç»“æ„ä½“**ã€‚

ä»¥ OpenAI çš„ GPT-4 tool call å®ç°ä¸ºä¾‹ï¼Œå½“å®ƒè§‰å¾—éœ€è¦è°ƒç”¨æŸä¸ªå·¥å…·æ—¶ï¼Œä¼šç›´æ¥è¾“å‡ºç±»ä¼¼è¿™æ ·çš„ç»“æ„ï¼š

```json
{
  "tool_calls": [
    {
      "id": "call_abc123",
      "function": {
        "name": "get_weather",
        "arguments": "{ \"location\": \"Beijing\" }"
      },
      "type": "function"
    }
  ]
}
```

è¿™ä¸ªç»“æ„å¹¶ä¸ä¼šç”±å¼€å‘è€…æ‰‹åŠ¨å†™ï¼Œè€Œæ˜¯æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆçš„ã€‚
 
### ğŸ”„ **è°ƒç”¨æµç¨‹ç®€è¦æè¿°ï¼š**

1. **å®šä¹‰å·¥å…·ï¼ˆfunctions/toolsï¼‰**
   åœ¨è°ƒç”¨å‰ï¼Œå¼€å‘è€…éœ€è¦é¢„å…ˆå‘ LLM æä¾›ä¸€ç»„ tools çš„å®šä¹‰ï¼ŒåŒ…æ‹¬åç§°ã€å‚æ•°ã€å‚æ•°ç±»å‹ï¼ˆé€šå¸¸æ˜¯ JSON Schemaï¼‰ï¼Œä»¥åŠç®€è¦æè¿°ã€‚åƒè¿™æ ·ï¼š

   ```json
   {
     "name": "get_weather",
     "description": "Get the current weather of a city",
     "parameters": {
       "type": "object",
       "properties": {
         "location": {
           "type": "string",
           "description": "City name"
         }
       },
       "required": ["location"]
     }
   }
   ```

2. **æ¨¡å‹è¾“å‡ºè°ƒç”¨ç»“æ„**
   ä¸€æ—¦æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡ä¸­åˆ¤æ–­åº”è¯¥è°ƒç”¨æŸå·¥å…·ï¼Œå®ƒä¼šç›´æ¥è¾“å‡ºä¸Šè¿° JSON è°ƒç”¨ç»“æ„ï¼Œè€Œä¸æ˜¯æ™®é€šçš„æ–‡æœ¬å›ç­”ã€‚

3. **ç”±è°ƒç”¨å™¨æ‰§è¡Œå·¥å…·**
   æ”¶åˆ°è°ƒç”¨ç»“æ„åï¼Œå¤–éƒ¨ç¨‹åºï¼ˆæ¯”å¦‚ API å®¢æˆ·ç«¯ï¼‰ä¼šè§£æè¿™ä¸ª JSONï¼Œå»æ‰§è¡Œå¯¹åº”çš„å‡½æ•°æˆ– APIã€‚

4. **å†æŠŠç»“æœä¼ å›æ¨¡å‹**
   å·¥å…·æ‰§è¡Œå®Œæˆåï¼Œå°†è¿”å›çš„ç»“æœï¼ˆä¹Ÿé€šå¸¸æ˜¯ JSONï¼‰é‡æ–°ä¼ ç»™ LLMï¼Œç”±å®ƒç”Ÿæˆæœ€ç»ˆçš„è‡ªç„¶è¯­è¨€å›ç­”ã€‚
 

### ä¸¾ä¾‹è¯´æ˜

**ç”¨æˆ·è¾“å…¥ï¼š**

> What's the weather like in Tokyo today?

**æ¨¡å‹è¾“å‡ºï¼ˆtool callï¼‰ï¼š**

```json
{
  "tool_calls": [
    {
      "id": "call_001",
      "function": {
        "name": "get_weather",
        "arguments": "{ \"location\": \"Tokyo\" }"
      },
      "type": "function"
    }
  ]
}
```

**å¤–éƒ¨è°ƒç”¨ tool å¹¶è·å–ç»“æœï¼Œè¿”å›æ¨¡å‹ï¼š**

è¿™ä¸€æ­¥ç»™åˆ° LLM çš„æ—¶å€™ï¼Œä¸€èˆ¬ä¼šä»¤ role = toolï¼š

```json
{
  "tool_responses": [
    {
      "tool_call_id": "call_001",
      "output": {
        "location": "Tokyo",
        "temperature": "30Â°C",
        "condition": "Sunny"
      }
    }
  ]
}
```

**æ¨¡å‹å†è¾“å‡ºè‡ªç„¶è¯­è¨€ï¼š**

> The weather in Tokyo today is sunny with a temperature of 30Â°C.

----

### **claudeï¼š**

https://docs.anthropic.com/en/docs/agents-and-tools/tool-use/overview#single-tool-example

å¯ä»¥çœ‹åˆ°å¯¹äº claude æ¥è¯´ï¼šç¬¬3æ­¥æ²¡æŒ‰ role=tool å¤„ç†ï¼Œè€Œæ˜¯ ä»ç„¶æ˜¯ role=user

![image](https://github.com/user-attachments/assets/f86bec6c-fcc3-4800-8ef4-5dd234f0f1ee)

----

### 

å†çœ‹è¿™é‡Œï¼š https://medium.com/@developer.yasir.pk/tool-calling-for-llms-a-detailed-tutorial-a2b4d78633e2

![image](https://github.com/user-attachments/assets/c3cbcb9f-09e2-4e95-b075-2a06e6fa5b16)

============

# ç¤ºä¾‹
```
import os
import json
import datetime
import requests 

API_KEY = "sk-XXX"
BASE_URL = "https://xxxx.com/v1/chat/completions"


# å®šä¹‰å‡½æ•° schema
functions = [
    {
        "name": "calculate",
        "description": "æ‰§è¡Œä¸€ä¸ªæ•°å­¦è¡¨è¾¾å¼ï¼Œè¿”å›ç»“æœ",
        "parameters": {
            "type": "object",
            "properties": {
                "expr": {
                    "type": "string",
                    "description": "æ•°å­¦è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ '3+4*2'"
                }
            },
            "required": ["expr"]
        }
    },
    {
        "name": "get_current_date_time",
        "description": "è·å–å½“å‰ç³»ç»Ÿæ—¥æœŸä¸æ—¶é—´ï¼ˆ2022-02-22 01:22:33æ ¼å¼ï¼‰ã€‚",
        "parameters": {
            "type": "object",
            "properties": {}
        }
    }
]

def calculate(expr: str):
    """æ‰§è¡Œå­—ç¬¦ä¸²è¡¨è¾¾å¼ï¼Œè¿”å›ç»“æœ"""
    local_vars = {}
    exec(f"a = {expr}", {}, local_vars)
    print ("LLLexpr", expr, "ans", local_vars["a"])
    return local_vars["a"]

def get_current_time():
    """è¿”å›å½“å‰ç³»ç»Ÿæ—¶é—´å­—ç¬¦ä¸²"""
    now = datetime.datetime.now()
    return now.strftime("%Y-%m-%d %H:%M:%S")

def call_llm(messages):
    """å‘èµ· POST è¯·æ±‚"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}",
    }
    payload = {
        "model": "gpt-4.1",  # æ”¹æˆä½ çš„æ¨¡å‹åç§°
        "messages": messages,
        "functions": functions,
        "function_call": "auto",
    }

    resp = requests.post(BASE_URL, headers=headers, data=json.dumps(payload))
    if resp.status_code != 200:
        print("è¯·æ±‚å¤±è´¥:", resp.status_code, resp.text)
        return None
    return resp.json()

def run_chat():
    messages = [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªèƒ½è®¡ç®—æ•°å­¦è¡¨è¾¾å¼çš„åŠ©æ‰‹"}]

    while True:
        user_input = input("ä½ ï¼š").strip()
        if user_input.lower() in ("é€€å‡º", "exit", "quit"):
            print("ç³»ç»Ÿï¼šå†è§ï¼")
            break

        messages.append({"role": "user", "content": user_input})
        resp = call_llm(messages)
        print ("  call_llm")
        if not resp:
            continue

        message = resp["choices"][0]["message"]
        print ('  first_call_result', message)

        # æ£€æŸ¥æ˜¯å¦è§¦å‘ function call
        if "function_call" in message:
            func_name = message["function_call"]["name"]
            args = json.loads(message["function_call"]["arguments"])
            if func_name == "calculate":
                result = calculate(args["expr"])
            elif func_name == "get_current_date_time":
                result = get_current_time()
            else:
                result = f"æœªçŸ¥å‡½æ•°: {func_name}"

            messages.append({
                "role": "function",
                "name": "calculate",
                "content": str(result)
            })

            # å†å‘ä¸€æ¬¡ï¼ŒæŠŠå‡½æ•°ç»“æœè¿”å›ç»™æ¨¡å‹ç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”
            final = call_llm(messages)
            print ('  call_LLM_again', final)
            if final:
                reply = final["choices"][0]["message"]["content"]
                print("åŠ©æ‰‹ï¼š", reply)
        else:
            print("åŠ©æ‰‹ï¼š", message.get("content"))


if __name__ == "__main__":
    run_chat()
```

æ‰§è¡Œï¼š

``` 
ä½ ï¼šå°ç‹å»ä¹°èœï¼Œä¸€æ–¤ç™½èœä¸€å—ä¹æ¯›äºŒï¼Œä¹°äº†äºŒæ–¤å…«ä¸¤ï¼Œä¸€å…±å¤šå°‘é’±
  <<  ä¸‹é¢æ˜¯ functional calling çš„ä¸¤æ¬¡è¿‡ç¨‹
  call_llm 
  first_call_result {'role': 'assistant', 'content': None, 'function_call': {'name': 'calculate', 'arguments': '{"expr":"1.92 * (2 + 8/16)"}'}, 'refusal': None, 'annotations': []}
LLLexpr 1.92 * (2 + 8/16) ans 4.8
  call_LLM_again {'id': 'chatcmpl-CTJvGFfYOxyBOkATUJhSbpaI45mbs', 'object': 'chat.completion', 'created': 1761104130, 'model': 'gpt-4.1-2025-04-14', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'ä¸€æ–¤ç™½èœ1.92å…ƒï¼Œä¹°äº†äºŒæ–¤å…«ä¸¤ï¼ˆ2.8æ–¤ï¼‰ï¼Œæ€»ä»·è®¡ç®—å¦‚ä¸‹ï¼š\n\n1.92 Ã— 2.8 = 5.376å…ƒ\n\næ‰€ä»¥ä¸€å…±éœ€è¦5.38å…ƒï¼ˆå››èˆäº”å…¥åˆ°åˆ†ï¼‰ã€‚', 'refusal': None, 'annotations': []}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 132, 'completion_tokens': 58, 'total_tokens': 190, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'system_fingerprint': 'fp_f99638a8d7'}
  >>
åŠ©æ‰‹ï¼š ä¸€æ–¤ç™½èœ1.92å…ƒï¼Œä¹°äº†äºŒæ–¤å…«ä¸¤ï¼ˆ2.8æ–¤ï¼‰ï¼Œæ€»ä»·è®¡ç®—å¦‚ä¸‹ï¼š

1.92 Ã— 2.8 = 5.376å…ƒ

æ‰€ä»¥ä¸€å…±éœ€è¦5.38å…ƒï¼ˆå››èˆäº”å…¥åˆ°åˆ†ï¼‰ã€‚
```
