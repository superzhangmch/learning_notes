《GPTQ: ACCURATE POST-TRAINING QUANTIZATION FOR GENERATIVE PRE-TRAINED TRANSFORMERS》 https://arxiv.org/pdf/2210.17323

GPTQ 继承自 OBQ(Optimal Brain Quantization，2022), 而 OBQ 又是来自 OBS（Optimal Brain Surgeon，1993）。

这一类方法做的是训练后的量化。它针对的是 inference 中的矩阵乘法的权重，而不管激活。它的基本思路是，选一批随机 sample 做 inference，从而可以得到每一个矩阵乘中的激活 input X。对网络中的一个具体权重矩阵 W，寻找最佳量化 $\hat{W}$ 满足 $\text{argmin}_{\hat{W}} ∥W X − \hat{W} X∥_2^2$。

也就是说，用它做量化时，不关心网络结构是什么，原始 loss 是什么，而只需要知道一个权重 W 的典型 input X 啥样，就可以对 W 做量化。

GPTQ 文中试了 4 bit, 乃至于 2 bit 量化。

----

## 理论

发展脉络是 OBS => OBQ => GPTQ。但是背后的基本原理是一样的。看一些资料，OBS 是想把不重要的权重给置零，OBQ 是用同样的参数筛选方式，但是不是置零而是量化之。这里只看 GPTQ paper 中介绍的 OBQ。

### OBQ - Optimal Brain Quantization，2022

如前所述，它只处理矩阵乘法，且只处理里面的权重。对一个具体权重矩阵 W，它的量化策略是，寻找 $\hat{W}=quant(W)$ 使得 $\hat{W}$ 满足 $∥W X − \hat{W} X∥_2^2$ 最小，其中 X 是一批样本做 inference 得来。

鉴于量化后的 $\hat{W}$ 是 “量化“的，也就是有限取值离散的，所以按说全遍历搜索一下，也能得到最佳 $\hat{W}$ 取值。当然这会比较低效。所以 OBS/OBQ 在于有一套方法，能更高效低做，当然它的最终解法并不是全局最优解。



----

## 实际操作

（1）、对于一个参数，怎么量化它的？用 scaling 吗

（2）、
