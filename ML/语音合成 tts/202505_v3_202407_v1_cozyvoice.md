- cosyvoice.v1: https://arxiv.org/abs/2407.05407 《CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens》
- cosyvoice.v2: https://arxiv.org/pdf/2412.10117 《CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models》
- cosyvoice.v3: https://arxiv.org/pdf/2505.17589v1 《CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training》

总体而言，乃【text => 自回归得到 speech tokens => flow-match 得到mel谱 => vocoder 得到 audio】流程。与 seed-TTS 一样。但是自回归部分乃从通用 LLM 微调而来。

---

# v1

### （1）、原理

![image](https://github.com/user-attachments/assets/8c03851e-e057-465f-b89d-6a1cf53ac5d4)

- 流程：text => 自回归得到 speech tokens => flow-match 得到mel谱 => vocoder 得到 audio。与 seed-TTS 一样。
- tokenizer：把 SenseVoice ASR 模型中间加入 VQ （vector quantization）层后 finetune 得到。
- 说话人向量（图中v)：既要给到 LM，也要给到 flow-match
- flow-matching：
  - 它有一个特殊条件input： masked speech feature $\tilde{X}$，在 cosyvoice2 中有图形象说明了它长什么样：
    - ![image](https://github.com/user-attachments/assets/c06231be-6c0e-42f3-b71d-8906f90ad96f)
    - 也就是说，是把目标 mel-谱（也就是 noise=> ori_mel_spectral中ori一端) 尾部 mask 掉随机长度，对这段置零。这样是为了能支持 audio prompt（用于Zero-shot In-context Learning，见下面）。
  - 会用到 Classifier-free guidance (CFG)

### （2）、Zero-shot In-context Learning

![image](https://github.com/user-attachments/assets/9b38de05-4be3-46cb-b157-b1a6a4ac38b2)

# v2

![image](https://github.com/user-attachments/assets/527d840e-e192-430b-98b2-08cd9f323c8a)

### 改进
- LM：换成了直接从别处 pretraining 的通用 LLM（Qwen2.5-0.5B）
  - speaker embedding 不再 feed 到 LLM（防止 information leaking）
- flow-matching：
  - 可以分块流式生成。
  - ![image](https://github.com/user-attachments/assets/7a3f9ba1-d5e6-422b-a47c-6a24e9160024)
- tokenizer：
  - 由 VQ 方式变成 FSQ 方式。但仍用 ASR 作监督。
    - FSQ：先降维再升维，对于中间的瓶颈位置向量取整作为 audio token。
    - ![image](https://github.com/user-attachments/assets/b44a1b59-05b4-4060-8d59-d2d14685478d)
  - 为啥有此升级：
    - 原始 VQ 的 codebook 利用率低（仅 23%），而 FSQ 能做到 100%。
    - FSQ 保留了更多语义信息（能导致下游 ASR 的错误率显著下降）
    - FSQ 量化后，speaker 信息被去除得更干净
    - 等
- 流与非流的统一：

# v3

![image](https://github.com/user-attachments/assets/341ccadb-5871-46eb-9664-893200fd9b71)

---

## 下面是 AI 总结的各版本差异：

### LM

| 版本 | LM 参数量   | 说明              |
| -- | -------- | --------------- |
| v1 | 未明确说明    | 自定义 LM（非预训练）    |
| v2 | **0.5B** | 使用 Qwen2.5-0.5B |
| v3 | **1.5B** | 更大容量，性能提升明显（来源未说）     |

### tokenizer

| 语音 Tokenizer    | CosyVoice v1         | CosyVoice v2                                    | CosyVoice v3                                                     |
| ---------------- | -------------------- | ----------------------------------------------- | ---------------------------------------------------------------- |
| **Token类型**      | 向量量化（VQ）token        | 有限标量量化（**FSQ**）token                            | 多任务监督训练的 FSQ token（**FSQ + MinMo**）                              |
| **Token生成方式**    | 自监督 ASR Encoder + VQ | **FSQ module** 插入 ASR Encoder，token rate = 25Hz | **FSQ module 插入 MinMo encoder**，用多任务监督训练（ASR, SER, LID, AED, SA） |
| **训练方式**         | 自监督                  | 单任务监督（ASR）                                      | **多任务监督**，530K 小时跨语言/风格音频                                        |
| **对 prosody 支持** | 较弱，依赖后续模型还原          | 中等，有部分 prosody 支持                               | 强，通过多任务建模提升语调、节奏、情绪建模                                            |
| **信息包含**         | 含有语义和音色，但上下文能力弱      | 增强了语义保留，但不关注情绪、事件                               | 同时编码 **语义 + 说话人 + 情绪 + 音事件**                                     |
| **token 表达维度**   | VQ 多codebook高维表达     | FSQ 单 codebook，低维标量表达                           | FSQ + MinMo，高保真低码率，强化可控性                                         |
| **Codebook利用率**  | 仅约 23%（低）            | **100%**（通过 FSQ）                                | 保持 100%，并扩展功能属性                                                  |
| **Token Rate**   | 未明确（估计较高）            | 25Hz                                            | **25Hz**（每秒25个token）                                             |

### Flow-Matching 对比（speech tokens → mel）

| 项目            | CosyVoice v1                | CosyVoice v2                             | CosyVoice v3                        |
| ------------- | --------------------------- | ---------------------------------------- | ----------------------------------- |
| **名称**        | Flow Matching (CFM)         | Chunk-aware Causal Flow Matching (C-CFM) | C-CFM + Diffusion Transformer (DiT) |
| **支持流式生成**    | ❌ 不支持                       | ✅ 支持 bi-directional streaming            | ✅ 支持，多语言多风格下流式鲁棒性更强                 |
| **Chunk机制**   | ❌ 无                         | ✅ 显式 chunk 划分                            | ✅ 支持 chunk，同时增强跨 chunk 上下文建模        |
| **注意力 Mask**  | ❌ 无                         | ✅ 多种 causal mask：half/left/bidirectional | ✅ 同 v2，保留并优化 mask 设计                |
| **结构基础**      | 标准 Transformer Flow Decoder | Transformer + Chunk-aware FM             | ✅ 改为 **DiT**（更强、更稳定）                |
| **长度对齐方法**    | 显式对齐模块                      | 对齐模块（duration-aware）                     | ✅ 去除对齐模块，改用插值对齐（更简洁）                |
| **强化学习支持**    | ❌ 无                         | ❌ 无                                      | ✅ 支持 DiffRO 奖励驱动，提升内容一致性            |
| **模型规模（参数量）** | 小                           | 中（100M）                                  | 大（300M）                             |

### Vocoder 模块对比（mel → waveform）

| 项目             | CosyVoice v1     | CosyVoice v2    | CosyVoice v3                        |
| -------------- | ---------------- | --------------- | ----------------------------------- |
| **Vocoder 类型** | HiFi-GAN（标准）     | HiFi-GAN（改进版）   | ✅ HiFi-GAN 或等效高质量 vocoder（未改变架构）    |
| **输入来源**       | FM生成的 mel（质量较一般） | 更优的流式 FM 生成 mel | ✅ 高保真 mel（来自 FSQ + 多任务 token + DiT） |
| **是否流式合成支持**   | ❌ 不支持            | ✅ 可用于流式合成       | ✅ 兼容流式，质量更稳更高                       |
| **声学细节保真度**    | 一般               | 中等              | ✅ 更高（mel 来自更强 FM）                   |
| **附加控制能力**     | ❌ 无              | ❌ 无             | ✅ 间接支持情绪/语速/风格（通过 token → mel 的表达力） |
