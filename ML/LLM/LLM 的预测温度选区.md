一般性任务各种模型都无脑用 0.7~1，一般是没啥问题的。不过最好看下model 推荐的温度。

对于希望确定性输出的任务，把 temperature 设置为接近于0，甚至就是0，一般也没啥问题，甚至推荐这样做（比如 output 是直接给出简短的是否判断的。或者 llm 本身用来评判一些结果的对错的）。设置为0和设置为0.7等值比，大量跑下，model 的平均效果差不多，而低温度会更好。有 paper 讲这个，一时找不到是哪篇。

对于写作文等生成任务，无疑需要更大的温度。
