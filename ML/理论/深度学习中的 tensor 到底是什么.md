# 深度学习中的 tensor 到底是什么

tensorflow / pytorch 中的 tensor（张量） 就是多维数组。多维数组确实可以认为就是个张量。

直和的数学符号是⊕，而张量积的数学符号是⊗。两个向量空间的直和的维数等于两个空间维数和，而两个向量空间的张量积的维数等于两个空间维数的乘积。从这个意义上，直和和张量积的符号确实就应该是这样子的。

特意翻了下当年看过学过而今全忘了的书。张量积空间本身的数学定义是十分拗口的：
```
  V × W ────φ────> V ⊗ W
   \               |
    \              |
     h           hat(h)
      \            |
       \           |
        └────────> 𝒵
```
其中 V、W 是线性空间，Z是任意的线性空间，带波浪线头的 h 是个线性变换，h与 φ 都是双线性映射。

可以证明，存在唯一的 φ 与 线性空间 V_W（双线性映射的像不是线性空间，所以应该说 V_W 其实是 φ 的像生成的空间） 使得对任意的 Z 与 h，上面的交换图成立。这个 V_W 就是张量 V⊗W。

从基的角度，结合上述交换图，可知 V⊗W 的基正是{ $v_i⊗w_j$ }（假设{ $v_i$ }、{ $w_j$ }分别是V与W的基）。

见：https://en.wikipedia.org/wiki/Tensor_product

