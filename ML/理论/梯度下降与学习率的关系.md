# 机器学习之梯度下降与学习率的关系 

梯度下降目的是找参数调整的方向，学习率连同梯度模长决定在该方向上的参数改变量。

### 1. 梯度决定方向
如果是一维函数求极值，那么方向不是左就是右。对于高维函数，梯度梯度就是要给出具体的矢量化的前进方向。在指出方向这点上，梯度矢量的模长是没任何用的。

### 2. 学习率连同梯度模长决定步长
我们往往希望，在离极值点远的地方，能够前进步长更长些，离极值点近的地方，则步长短些，小步前进。在极值点足够近的区域内，矢量的模长确实是有这个性质的（想想极值点附近，切线足够平）。也正是因为这个原因，所以参数调整公式可以写为： 
> $w_{i+1} = w_i -  \frac {dL}{dw}$ 

(注意 w 与 gradient 都是多维矢量)，距离极值点很近之外的地方，梯度的模取值可能很大，也就是可能至少有一个维度上取值很大，这时候按上述公式的话，一次的步进就可能会太长了。所以需要引入学习率来对此作出控制：
> $w_{i+1} = w_i -  \frac {dL}{dw} \cdot lr$

理想的步长是该长则长该短则短，但这是不好控制的。所以才有了各种方法对学习率作各种优化。这就不提了。
