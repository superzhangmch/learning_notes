
下面主要是 AI 给出：


## 一、典型方法：从早期Siamese到SimCLR

### 1. 早期阶段（Siamese Network）

* **代表作：** Siamese Network（Bromley et al., 1993）
* **应用：** 签名验证、人脸识别（如 FaceNet）
* **特点：** 成对输入（anchor-positive/negative），优化距离度量。

### 2. 度量学习阶段

* **代表作：** Triplet Loss（Schroff et al., 2015, FaceNet）： `Loss = max(0,d(a,p)−d(a,n)+α)`。在主流的自监督对比学习框架中已经很少使用了。
* **思想：** 同类样本比异类样本更近一个 margin。

### 3. 自监督对比学习阶段（2018–2020）

* **关键突破：** 不需要人工标签，只需**数据增强构造正样本**。
* **代表方法：**

  * **SimCLR（Chen et al., 2020）**：通过随机增强生成正样本对，引入大 batch 和投影头结构；
  * **MoCo（He et al., 2020）**：引入**动量编码器**和**队列机制**缓解大 batch 需求；
  * **BYOL（Grill et al., 2020）**：去掉负样本，仅依靠自蒸馏（teacher-student 模型）仍能学出良好表示；
  * **SimSiam（Chen & He, 2021）**：进一步简化，表明停止梯度即可防止塌陷。

## 二、发展阶段与研究脉络

| 阶段      | 时间        | 代表工作                         | 特点与贡献                     |
| ------- | --------- | ---------------------------- | ------------------------- |
| 度量学习阶段  | 2013–2017 | Triplet Loss, N-pair Loss    | 有标签、对比类间距离                |
| 自监督对比学习 | 2018–2020 | SimCLR, MoCo, BYOL           | 无标签、通过增强生成正样本             |
| 半监督与多模态 | 2020–2022 | CLIP, ALIGN, SLIP            | 图像-文本对齐、多模态对比             |
| 大模型融合阶段 | 2022–至今   | CLIP, SimMIM, DINOv2, I-JEPA | 对比思想融入 Transformer、大规模预训练 |

## 三、最新进展与趋势（2023–2025）

### 1. **多模态对比学习**

* **代表作：** CLIP（OpenAI, 2021）
  利用大规模图文对进行跨模态对齐，成为多模态理解和生成的核心基础。
* 后续如 **BLIP, ALIGN, EVA-CLIP, SigLIP** 等持续改进对齐方式和鲁棒性。

### 2. **对比学习 + 掩码建模结合**

* 如 **iBOT、Milan、MVP** 将对比损失与 Masked Image Modeling（MIM）结合，
  兼顾局部结构与全局语义。

### 3. **语义空间的统一化**

* 新趋势是使用**对比学习作为统一表征框架**，对齐视觉、语言、动作、音频等模态。
* **OpenCLIP、Uni-Perceiver、EVA、Flamingo** 等模型均在此方向上发展。

## 四、小结

| 层面   | 关键思想        | 代表方法          | 当前趋势      |
| ---- | ----------- | ------------- | --------- |
| 表征学习 | 相似样本靠近、异类远离 | SimCLR、MoCo   | 理论化与大模型融合 |
| 数据类型 | 从单模态到多模态    | CLIP、ALIGN    | 视觉-语言统一对齐 |
| 优化方式 | 从负样本驱动到自蒸馏  | BYOL、SimSiam  | 去负样本化趋势   |
| 应用场景 | 从分类到生成      | DINOv2、I-JEPA | 与生成模型结合   |

---

人脸识别：

- 现代人脸识别（face recognition） 已经经历了从 Triplet Loss → ArcFace 等角度损失（Angular Margin Loss） → 对比/自蒸馏表征学习 的演进。
- 主流人脸识别（face recognition）模型目前仍然不直接使用 InfoNCE loss，但 InfoNCE 的思想（对比学习思想）已经“渗透”进来了，在若干变体或辅助模块中被采用。
