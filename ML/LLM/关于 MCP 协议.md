
ä¸€è¯´åˆ° MCPï¼Œå°±ä¼šè¯´å®ƒæœ‰ hostã€clientã€server ä¸‰éƒ¨åˆ†ã€‚å®ƒæ˜¯ä¸ºäº†æ–¹ä¾¿ LLM ä»¥ç»Ÿä¸€æ–¹å¼è°ƒç”¨å¤–éƒ¨å·¥å…·è€Œè®¾è®¡çš„ï¼Œé‚£ä¹ˆè¿™ä¸‰è€…æ€æ ·å…³ç³»ï¼Œä»¥åŠæ€ä¹ˆå’Œ LLM ç»“åˆèµ·æ¥ï¼Œå…¶å®å¾ˆæ˜¯å¾ˆæ‰‘æœ”è¿·ç¦»çš„ã€‚

å…¶å® MCP åªæ˜¯å®šä¹‰äº† client ä¸ server ä¹‹é—´çš„ç½‘ç»œäº¤äº’åè®®ï¼Œè¿™éƒ¨åˆ†æ˜¯æ­»çš„ã€‚å…¶ä»–éƒ¨åˆ†å¹¶æ²¡ä¸¥æ ¼è§„å®šï¼Œå…·ä½“æ€ä¹ˆå®ç°æ— ä¸€å®šä¹‹è§„ã€‚

å®˜ç½‘æ–‡æ¡£ï¼š https://modelcontextprotocol.io/

**ç®€ä»‹:**
- **server**ï¼šåªæ˜¯å¯¹äºå„ç§åç«¯èµ„æºåšäº†ç»Ÿä¸€æ¥å£çš„å°è£…ã€‚æ‰€ä»¥ server å…¶å®æ˜¯è–„è–„ä¸€å±‚ã€‚server ä¸ä¼šè¯·æ±‚ LLMï¼Œå½“éœ€è¦çš„æ—¶å€™ï¼Œé€šè¿‡åå‘è®© client ç”¨ sampling æ¥å®Œæˆï¼ˆclient è½¬å‘ç»™ host ä½œ LLM é‡‡æ ·ï¼‰ã€‚
- **client**ï¼šåªæ˜¯è´Ÿè´£ä¸ mcp server çš„äº¤äº’ã€‚å®ƒæ˜¯ä¾› host ä½¿ç”¨çš„ï¼Œæš´éœ²ç»™ host çš„æ ¸æ¥å£ï¼Œéƒ½æ˜¯æ€ä¹ˆä¸ server æ‰“äº¤é“çš„ï¼Œæ‰€ä»¥æ ¸å¿ƒæ¥å£å…¶å®å°±æ˜¯ï¼šserver çš„ toolã€resourceã€prompt ä¸‰ç§èµ„æºçš„ listï¼Œä»¥åŠ getã€‚
  - å³æš´éœ²ç»™ä¸Šæ¸¸ host çš„æ ¸å¿ƒæ¥å£æ˜¯ï¼š list_resourcesï¼Œ list_toolsï¼Œ list_promptsï¼Œ read_resourceï¼Œ call_toolã€‚ä½†æ˜¯è¿™äº›æ¥å£å±äº host å¤©ç„¶éœ€è¦çš„ï¼Œä½†æ˜¯å®ƒä»¬é•¿ä»€ä¹ˆæ ·ï¼ˆåå­—ã€å‚æ•°ç­‰ï¼‰ï¼Œå¹¶ä¸æ˜¯ mcp åè®®çš„ä¸€éƒ¨åˆ†ã€‚è€Œå–å†³äºä½ æ€ä¹ˆå®ç°å®ƒã€‚ 
  - client æœ¬èº«ä¹Ÿæ˜¯è½»é‡çš„ï¼Œä¸ä¸ LLM æ‰“äº¤é“ã€‚
- **host**ï¼šå³åº”ç”¨æœ¬èº«ï¼ˆæ¯”å¦‚ ai ç¼–ç¨‹ IDEï¼‰ã€‚åº”ç”¨é€šè¿‡ client æä¾›çš„ç»Ÿä¸€æ¥å£å’Œ server ä»¬æ‰“äº¤é“ã€‚
  - host æŒæ§ LLMï¼Œå®ƒå¼•å¯¼ç”¨æˆ·å’Œ host çš„äººæœºäº¤äº’ç•Œé¢çš„äº¤äº’ï¼Œå¹¶é©±ä½¿ LLM ä½œå›ç­”ã€æ™ºèƒ½é€‰æ‹©å·¥å…·ç­‰ç­‰ã€‚
  - ç‰¹åˆ«çš„ï¼Œå¯¹äº server æä¾›çš„é‚£äº› toolã€resourceã€prompts èµ„æºï¼ˆç”šè‡³ host å¯ä»¥è¿å¥½å¤šä¸ª clients, å¥½å¤šä¸ª serversï¼‰ï¼Œéœ€è¦é€‰æ‹©æ°å½“çš„é‚£äº›ç”¨äºå¤„ç†ç”¨æˆ·å½“å‰è¯·æ±‚ã€‚è¿™ä¸ª tool/resource/prompt selection çš„å·¥ä½œï¼Œæ˜¯ host æ¥åšçš„ã€‚

<img width="728" height="516" alt="image" src="https://github.com/user-attachments/assets/4be8ca20-fa5c-4a6b-801d-556dd9f146b7" />

**ä»£ç å®ç°ï¼Œæ€ä¹ˆåšï¼š**
- serverï¼šå¯¹äºæ¯ä¸€ä¸ª serverï¼ŒæŒ‰ç…§ mcp åè®®å®ç°å³å¯ã€‚
- clientï¼šå›ºç„¶å¯ä»¥æŒ‰ç…§ mcp åè®®è‡ªå·±å®ç°ã€‚ä½†æ˜¯åªè¦ server ç¬¦åˆ mcp åè®®ï¼Œå®ç°å®Œå¥½çš„ client ä¸€å®šå¯ä»¥æ”¯æŒå®ƒã€‚æ‰€ä»¥ client ä¸éœ€è¦é‡å¤é€ è½®å­ï¼Œç”¨åˆ«äººå®ç°å¥½çš„å°±è¡Œâ€”â€”æ¯”å¦‚å®˜ç½‘å®ç°çš„ï¼šhttps://github.com/modelcontextprotocol/python-sdk/blob/main/src/mcp/client/session.py ï¼Œå³ mcp.ClientSessionã€‚å¯¹äºå®˜ç½‘ä¾‹å­ https://github.com/modelcontextprotocol/python-sdk/blob/main/examples/clients/simple-chatbot/mcp_simple_chatbot/main.py æ¥è¯´ï¼Œ è¿™é‡Œæ˜¯åœ¨ä½¿ç”¨ mcp.ClientSessionï¼Œæ‰€ä»¥ä¸¥æ ¼è¯´æ¥ï¼Œå®ƒå…¶å®æ˜¯å®ç°äº†ä¸€ä¸ª hostï¼Œè€Œé clientã€‚
- hostï¼šä¸Šé¢æåˆ°çš„ https://github.com/modelcontextprotocol/python-sdk/blob/main/examples/clients/simple-chatbot/mcp_simple_chatbot/main.py å°±æ˜¯ä¸€ä¸ªä¾‹å­ã€‚é€šè¿‡ä½¿ç”¨ mcp.ClientSessionï¼Œå®ç°äº†ä¸€ä¸ªå…·æœ‰é¢å‘ç”¨æˆ·çš„æœ‰å®é™…åŠŸèƒ½çš„ hostã€‚

**å’Œfunction calling å…³ç³»:**

function calling å’Œ mcp åè®®æœ¬èº«æ²¡å…³ç³»ã€‚ä½†æ˜¯ function calling å¯ä»¥è¢« host ä½¿ç”¨ï¼Œç”¨æ¥é€‰æ‹©è°ƒç”¨ mcp.client -> mcp.server é“¾è·¯æä¾›çš„å·¥å…·ã€‚

----

# mcp-server

## mcp server å’Œ LLM çš„å…³ç³»

MCP Server å†…éƒ¨é€šå¸¸ä¸åŒ…å« LLM çš„ä½¿ç”¨ã€‚server æ˜¯ä¸€ä¸ªè½»é‡çº§çš„æ¥å£å±‚ï¼ˆå¯¹æ¥æ–‡ä»¶ç³»ç»Ÿã€æ•°æ®åº“ç­‰ï¼‰ï¼Œè€Œä¸æ˜¯æ™ºèƒ½å¤„ç†å±‚ã€‚

å¦‚æœ mcp server è¦è¯·æ±‚ LLMï¼Œå›ºç„¶å¯ä»¥ç›´æ¥è¯·æ±‚æŸä¸€ä¸ª LLMï¼Œä½†æ˜¯æŒ‰ mcp çš„åšæ³•ï¼Œæ˜¯ server å‘ client å‘èµ· sampling è¯·æ±‚ï¼ˆLLMè°ƒç”¨è¯·æ±‚ï¼‰ï¼Œè®© client æŠŠ LLM ç»“æœè¿”å›ç»™è‡ªå·±ã€‚

è¿™æ ·åšè®© server å’Œ LLM è°ƒç”¨è§£è€¦ï¼Œ client å¯ä»¥æ§åˆ¶ LLM çš„è°ƒç”¨ï¼šä¸€ä¸ªæ˜¯ LLM api çš„é€‰æ‹©ä¸é‰´æƒé—®é¢˜ï¼Œè¿˜æœ‰æ˜¯å¯ä»¥ç»™ç”¨æˆ·ä»¥å®‰å…¨æ€§æ§åˆ¶ï¼ˆhuman-in-the-loop)ï¼‰ï¼šç”¨æˆ·å¯ä»¥æ£€æŸ¥ server çš„ prompt ä»¥åŠ LLM çš„ ç»“æœï¼Œç”¨æˆ·è§‰å¾—æœ‰é—®é¢˜å¯ä»¥é˜»æ­¢ã€‚

## mcp server çš„ tools åŠŸèƒ½

- https://modelcontextprotocol.io/docs/concepts/tools
- https://modelcontextprotocol.io/specification/2025-06-18/server/tools

è¿™æ˜¯æœ€åŸºæœ¬åŠŸèƒ½ã€‚server éœ€è¦æœ‰æ¥å£ï¼Œèƒ½è®© client æŸ¥è¯¢æœ‰å“ªäº› toolsï¼ˆæ¯ä¸ªå·¥å…·æœ‰è¯¦ç»†æè¿°ï¼‰ï¼Œè¿™æ ·å…·ä½“ä»»åŠ¡æ¥äº†ï¼Œä¸Šæ¸¸æ‰èƒ½çŸ¥é“ä½¿ç”¨å“ªä¸ªå·¥å…·ã€‚

ä¸Šæ¸¸å¯èƒ½å‘ç°æœ‰å¾ˆå¤š toolsï¼Œæ€ä¹ˆé€‰æ‹©æœ¬æ¬¡è¯·æ±‚ç”¨å“ªä¸€ä¸ªå‘¢ï¼Ÿ
- function calling
  - æŒ‰å®˜ç½‘ä¾‹å­ https://modelcontextprotocol.io/quickstart/client ï¼š
  - <img height="700" alt="image" src="https://github.com/user-attachments/assets/cd8eda51-1290-4e16-8445-56bb15e61224" />
- tools æè¿°æ‹¼åˆ° prompt é‡Œ, ç”± LLM æ¥é€‰
  - æŒ‰å®˜ç½‘ä¾‹å­ https://github.com/modelcontextprotocol/python-sdk/blob/main/examples/clients/simple-chatbot/mcp_simple_chatbot/main.py
  - <img height="600" alt="image" src="https://github.com/user-attachments/assets/1201bd32-90ef-47ca-9887-049da49eb2f0" />
- å¦‚æœ tools éå¸¸å¤šï¼Œä¹ƒè‡³äºå‡ åä¸Šç™¾ï¼Œå…¨éƒ¨ç»™åˆ° LLM å°±ä¸å¤ªç°å®äº†ã€‚è¿™æ—¶å€™å¯èƒ½å°±éœ€è¦ä¸€ä¸ªé¢å¤–çš„å·¥å…·é€‰æ‹©æ­¥éª¤ï¼ŒæŠŠç²¾é€‰çš„å‡ ä¸ªå€™é€‰å·¥å…·ç»™åˆ° LLM
  - æ¯”å¦‚ https://arxiv.org/pdf/2505.03275 ï¼ˆRAG-MCPï¼‰æä¾›çš„æ–¹å¼ï¼Œå¯¹å·¥å…·å»ºç´¢å¼•ä½œæ£€ç´¢ï¼Œä¼˜é€‰å‡º top-k ä¸ªã€‚

## mcp server çš„ prompts åŠŸèƒ½

mcp server çš„ tool åŠŸèƒ½æ˜¯ç›´æ¥æ‰§è¡Œã€å¹² "å®Œ" ä¸€ä»¶äº‹ï¼Œè€Œ prompts åŠŸèƒ½ä¹Ÿå¯ä»¥è¯´æ˜¯å¹²ä¸€ä»¶äº‹ï¼Œåªæ˜¯ä¸åƒ tool è°ƒç”¨åå°±å¹²å®Œäº†ã€‚prompts åªæ˜¯è¿”å›äº†æ€ä¹ˆåšâ€”â€”å…·ä½“è¿˜éœ€ client æ‹¿åˆ°ç»“æœåè°ƒç”¨ä¸‹ LLMï¼ŒLLM ç»“æœæ‰ç®—æ˜¯è¿™æ¬¡ä»»åŠ¡çš„æ‰§è¡Œç»“æœã€‚

æŒ‰å®˜ç½‘æ–‡æ¡£ï¼Œprompts åº”è¯¥æ˜¯ç”¨æˆ·å¯æ§çš„ï¼Œéœ€è¦æš´æ¼ç»™ç”¨æˆ·ï¼Œç”±ç”¨æˆ·é€‰æ‹©æ‰§è¡Œï¼›å…¸å‹ä½¿ç”¨åœºæ™¯æ˜¯ UI ç•Œé¢ä¸Šç”±ç”¨æˆ·è§¦å‘ã€‚

- https://www.speakeasy.com/mcp/building-servers/advanced-concepts/prompts
- https://modelcontextprotocol.io/specification/2025-06-18/server/prompts
- https://modelcontextprotocol.io/docs/concepts/prompts

### ï¼ˆ1ï¼‰ã€client-server çš„æ•°æ®äº¤äº’

**client è¯¢é—® server æœ‰å“ªäº› prompt å¯ä½¿ç”¨ï¼š**
- client è¯·æ±‚ï¼š clientå‘èµ· method=`prompts/list` çš„è¯·æ±‚ã€‚
- server è¿”å›ï¼š
```
prompts_arr = [
      {
        "name": "code_review",
        "title": "Request Code Review",
        "description": "Asks the LLM to analyze code quality and suggest improvements",
        "arguments": [
          {
            "name": "code", # client å‘èµ· "method=prompts/get, name=code_review" çš„è¯·æ±‚æ—¶ï¼Œéœ€è¦å¡«å……çš„å‚æ•°
            "description": "The code to review",
            "required": true
          },
          {...}, ...å…¶ä»– prompt å‚æ•° (è‹¥æœ‰ï¼‰..., {...}
        ]
      },
      {...}, ... å…¶ä»– prompts ..., {...},
]
```
**é’ˆå¯¹å…·ä½“ä»»åŠ¡ï¼Œè¯·æ±‚è·å¾—å“åº”çš„ LLM promptï¼š**
- client è¯·æ±‚ï¼š clientå‘èµ· method=`prompts/get` çš„è¯·æ±‚ã€‚æ‰¿ä¸Šä¾‹å­ï¼Œè¦æä¾› `name=code_review`ï¼Œ å¹¶æä¾›å‚æ•°: `param.code=å…·ä½“çš„ä¸€æ®µä»£ç `ã€‚æä¾›çš„å‚æ•°ç”¨äºè®© server æ‹¼å‡ºæ°å½“çš„ promptã€‚
  - ä¸ºå•¥ client çŸ¥é“åœ¨è¿™ä¸ªåœºæ™¯ä¸‹æ­£å¥½è¯¥è¯·æ±‚ prompt_get è·å¾—æŸä¸ªname=xx çš„å…·ä½“ promptï¼Œè€Œéå…¶ä»–ï¼Ÿè¿™ä¸ªå±äºå†³ç­–é€‰æ‹©é—®é¢˜ï¼Œä¸‹é¢è®²ã€‚
- server è¿”å›ï¼šå¯ä»¥ä¾› LLM ç”¨ role=user ä½¿ç”¨çš„ä¸€æ®µ prompt: `Please review this Python code:\n{{code}}"`ï¼Œ code=è¯·æ±‚æ—¶æä¾›çš„ä»£ç 
  - æ ¹æ® https://modelcontextprotocol.io/specification/2025-06-18/server/prompts ï¼Œ https://modelcontextprotocol.io/docs/concepts/prompts ï¼Œå¯ä»¥ role=assistantï¼Œä¸”content å¯ä»¥ä¸åªæ˜¯ textï¼Œç”šè‡³å¯ä»¥æ˜¯ æ—¢æœ‰ useråˆæœ‰assistant(å³ä¸€ä¸ªèŠå¤©çš„ç‰‡æ®µ)ï¼š
    ```
    [
      {
        role: "user",
        content: {
          type: "text",
          text: `Here's an error I'm seeing: ${error}`,
        },
      },
      {
        role: "assistant",
        content: {
          type: "text",
          text: "I'll help analyze this error. What have you tried so far?",
        },
      },
      {
        role: "user",
        content: {
          type: "text",
          text: "I've tried restarting the service, but the error persists.",
        },
      },
    ];
    ```

<img width="2698" height="1496" alt="image" src="https://github.com/user-attachments/assets/cfe409f0-55e5-42ae-96af-03237ba90687" />

ï¼ˆä¸Šé¢ä¾‹è§ https://modelcontextprotocol.io/specification/2025-06-18/server/prompts ï¼‰

### ï¼ˆ2ï¼‰ã€prompt é€‰æ‹©

server çš„ prompts ä½¿ç”¨çš„æµç¨‹ä¸ºï¼š
- Discovery é˜¶æ®µï¼šClient é€šè¿‡ prompts/list è·å–æ‰€æœ‰å¯ç”¨çš„ prompts
- Selection é˜¶æ®µï¼šæ ¹æ®ç”¨æˆ·éœ€æ±‚æˆ–ç¨‹åºé€»è¾‘é€‰æ‹©åˆé€‚çš„ prompt
- Execution é˜¶æ®µï¼šè°ƒç”¨é€‰å®šçš„ prompt å¹¶ä¼ å…¥å¿…è¦å‚æ•°
- Response å¤„ç†ï¼šå¤„ç† LLM è¿”å›çš„ç»“æœ

é‚£ä¹ˆåœ¨ selection é˜¶æ®µï¼Œä¸ºå•¥ client çŸ¥é“åœ¨è¿™ä¸ªåœºæ™¯ä¸‹è¯¥è°ƒç”¨ prompt_get è·å¾—æŸä¸ª name=xx çš„å…·ä½“ promptï¼Œè€Œä¸æ˜¯è·å–å¦ä¸€ä¸ª name=yy çš„ï¼Œç”šè‡³ä¸ºä»€ä¹ˆä¸æ˜¯å»è°ƒç”¨æŸä¸ª toolï¼Ÿ

å¯ä»¥æœ‰ä¸¤ç§æ–¹å¼æ¥å†³å®šï¼š
- æå‰é™æ€ç»‘å®š
  - æ¯”å¦‚ç”¨æˆ·ç•Œé¢ä¸Šæœ‰ç›¸åº”çš„æŒ‰é’®æˆ–è€…é€‰é¡¹ï¼Œå·²ç»æå‰ç»‘å®šæ­»äº†å°±æ˜¯ code_reviewã€‚ç”¨æˆ·ä¸€æ—¦ç‚¹æ—‹å®ƒï¼Œå¿…ç„¶æ‰“å‘ `method=prompts/get with name=code_review`
  - æˆ–è€…æ¯”å¦‚æ ¹æ®ä¸€å®šä¸Šä¸‹æ–‡æ™ºèƒ½é€‰æ‹©ï¼Œè¿™æ—¶å€™è·Ÿè¸ªäº†ä»»åŠ¡çŠ¶æ€ï¼ŒçŸ¥é“è¿™æ—¶å€™æ˜¯åœ¨ code_review åœºæ™¯ï¼Œå½“ç„¶åªèƒ½æ‰“å‘å®ƒã€‚
- åŠ¨æ€é€‰å®šï¼šè®© LLM æ ¹æ®ç”¨æˆ·éœ€æ±‚åŠ¨æ€é€‰æ‹©åˆé€‚çš„ promptã€‚
  - æ¯”å¦‚ç”¨æˆ·è¯´â€œå¸®æˆ‘åˆ†æè¿™æ®µä»£ç çš„è´¨é‡â€ï¼Œ å°±åƒå·¥å…·çš„åŠ¨æ€é€‰æ‹©ä¸€æ ·ï¼Œç”± LLM è‡ªåŠ¨é€‰æ‹© prompt.name = code_review.

ä¸è¿‡å½“å‰å¤šç”¨é™æ€ç»‘å®šçš„æ–¹æ³•ã€‚

## mcp server çš„ resources

server æ”¯æŒ client æŸ¥è¯¢å®ƒæœ‰å“ªäº›èµ„æºï¼ˆresources/listï¼‰ï¼Œè¿™æ ·client æ‰çŸ¥é“æ€ä¹ˆç”¨ã€‚resources éƒ½æ˜¯é€šè¿‡ URI å½¢å¼æŒ‡å®šçš„ã€‚

ä¸Šæ¸¸æ€ä¹ˆçŸ¥é“å½“å‰åœºæ™¯ç”¨å“ªä¸ª resourceï¼ŸæŒ‰ https://modelcontextprotocol.io/specification/2025-06-18/server/resources ï¼Œæˆ–è€…é  UI ç•Œé¢å±•ç¤ºè®©ç”¨æˆ·ç‚¹é€‰ï¼Œæˆ–è€…é  ai æ¨¡å‹è‡ªåŠ¨é€‰æ‹©ã€‚

toolsã€promptsã€resources åŒºåˆ«ï¼š https://www.speakeasy.com/mcp/building-servers/advanced-concepts/prompts ï¼š 
<img width="1952" height="1102" alt="image" src="https://github.com/user-attachments/assets/0727d19a-0cb2-4827-8717-3f883e8758c2" />

----

# mcp-client

client é™¤äº†è¢« host ä½¿ç”¨ï¼Œè¿˜éœ€è¦æä¾› samplingã€rootsã€elicitation ç­‰æ¥å£ä¾› mcp server è°ƒç”¨ã€‚

### mcp client çš„ sampling

client ç»™ server æä¾›äº† LLM ä»£ç†è®¿é—®èƒ½åŠ›ã€‚

ç”¨æˆ·çš„ä»»åŠ¡ï¼Œä¸‹å‘åˆ° server åï¼Œå¦‚æœ server å‘ç°éœ€è¦å€ŸåŠ©äº LLMï¼Œå°±ä¼šå‘ client å‘èµ· samplingï¼Œæ‹¿åˆ°ç»“æœåï¼Œå†å‘ç»™ç”¨æˆ·ã€‚
 
- https://www.speakeasy.com/mcp/building-servers/advanced-concepts/sampling
- https://modelcontextprotocol.io/docs/concepts/sampling
- https://modelcontextprotocol.io/specification/2025-06-18/client/sampling

### mcp client çš„ rootsã€elicitation

**ï¼ˆ1ï¼‰ã€elicitationï¼š**

https://modelcontextprotocol.io/specification/2025-06-18/client/elicitation

åœ¨ client è°ƒç”¨æŸä¸ª server tool çš„æ—¶å€™ï¼Œserver ä¸çŸ¥é“æŸäº›ä¿¡æ¯ï¼Œéœ€è¦å‘ server å‘èµ· elicitation è¯·æ±‚ï¼Œä»¥ä¾¿è·å¾—è¿™äº›ä¿¡æ¯ã€‚

é‚£ä¹ˆï¼Œä¸ºä»€ä¹ˆ server ä¸åœ¨å®šä¹‰å®ƒçš„ tool å‚æ•°çš„æ—¶å€™ï¼Œå°±æŠŠè¿™äº›ä¿¡æ¯å®šä½å¿…é¡»å‘¢ï¼Ÿè¿™å¯èƒ½å› ä¸º server å†…å¤„ç†é€»è¾‘å¤æ‚ï¼Œä¸æ–¹ä¾¿ client ä¸€ä¸‹å­æŠŠå‚æ•°éƒ½æä¾›ï¼Œæˆ–è€…æ˜¯ä¸ºäº†å®‰å…¨å’Œéšç§è€ƒè™‘ã€‚

**ï¼ˆ2ï¼‰ã€rootsï¼š**

- https://modelcontextprotocol.io/specification/2025-06-18/client/roots
- https://modelcontextprotocol.io/docs/concepts/roots

roots è¿”å›ç»™ server ä¸€ä¸ªæˆ–å¤šä¸ª URI çš„ base åœ°å€ï¼ˆä¸åªé™äºæ–‡ä»¶ç³»ç»Ÿï¼‰ï¼š
```
{
  "roots": [
    {
      "uri": "file:///home/user/projects/frontend",
      "name": "Frontend Repository"
    },
    {
      "uri": "https://api.example.com/v1",
      "name": "API Endpoint"
    }
  ]
}
```

æœ‰é—®é¢˜æ˜¯ï¼Œä¸ºå•¥ä¸æ”¾åˆ° client è¯·æ±‚ server çš„å‚æ•°é‡Œï¼Œè€Œè¦è®© server ä¸»åŠ¨é—®ï¼Ÿ

æŒ‰ https://modelcontextprotocol.io/specification/2025-06-18/client/roots ï¼Œ Roots å®šä¹‰çš„æ˜¯ æ•´ä¸ª Server çš„å·¥ä½œè¾¹ç•Œï¼Œä¸æ˜¯æŸä¸ªå…·ä½“å·¥å…·çš„å‚æ•°, è€Œä¸”ä¸€æ¬¡è·å–å°±æŠŠå„ç§ç±»å‹èµ„æºçš„ roots æŒ‡å®šäº†ã€‚

----


**å…¶ä»–ä¸€äº›ç»†èŠ‚ï¼š**

<img width="1144" height="536" alt="image" src="https://github.com/user-attachments/assets/44226b34-18fa-458b-af99-da0fcdb93235" />

å¦‚ä¸Šï¼Œå»ºç«‹è¿æ¥åï¼Œé¦–å…ˆè¦åšä¸€ä¸ªâ€œé¦–æ¬¡æ¡æ‰‹â€ï¼Œ client ä¸ server å®£ç§°è‡ªå·±çš„èƒ½åŠ›ï¼Œä»¥åŠåè®®ç‰ˆæœ¬(è¿™éƒ½å°è£…åœ¨äº† py mcp.clientSession.initialize()é‡Œ)ã€‚è€Œ tools.listï¼Œ prompts.list ç­‰ï¼Œå¹¶ä¸æ˜¯åœ¨ initialize é˜¶æ®µå®Œæˆï¼Œè€Œæ˜¯ operation çš„äº‹ã€‚

æ­¤å¤–ï¼Œåè®®è¿˜è§„å®šéœ€è¦å¤„ç†å¤„ç† notificationã€subscribeã€åˆ†é¡µç­‰ã€‚æ¯”å¦‚ï¼Œinitialize çš„æ—¶å€™ï¼Œå°±å®£ç§°äº†å¯å˜é¡¹ï¼š
```
clientï¼š
      "roots": {
        "listChanged": true
      },
serverï¼š
      "prompts": {
        "listChanged": true
      },
      "resources": {
        "subscribe": true,
        "listChanged": true
      },
      "tools": {
        "listChanged": true
      }
```

å¦‚æœä¸­é€”æœ‰å˜æˆ–æœ‰æ›´æ–°ï¼Œéœ€è¦èƒ½é€šçŸ¥å¯¹æ–¹ï¼Œä¹Ÿå°±æ˜¯èƒ½çƒ­æ›´æ–°ã€‚

notification æœºåˆ¶ï¼šå½“èµ„æºçŠ¶æ€å˜åŒ–ï¼Œå®æ—¶äº‹ä»¶æ¨é€ï¼Œä»»åŠ¡è¿›åº¦ï¼ˆmethod=notifications/progressï¼‰ï¼Œé…ç½®å’Œç¯å¢ƒå˜åŒ–ç­‰è§¦å‘ã€‚ç‰¹åˆ«åœ¨ initialize() ä¸‰éƒ¨æ›²çš„æœ€åä¸€æ­¥å°±æ˜¯ä¸€ä¸ª notificationã€‚

ä»¥ä¸Šè¿™äº›ï¼Œéƒ½æ˜¯éœ€è¦ client ä¸ server çš„å®ç°éƒ½èƒ½æ”¯æŒåˆ°ã€‚

----

# client-server ç½‘ç»œè¿æ¥æ–¹å¼

å‚ï¼š https://modelcontextprotocol.io/specification/2025-06-18/basic/transports

<img width="1174" height="408" alt="image" src="https://github.com/user-attachments/assets/44970ba2-5ed0-4a4e-8f6e-a8f9c54896a7" />

å¦‚ä¸Šï¼Œstdio æ˜¯ client ä¸ server åŒæœºéƒ¨ç½²çš„è¿›ç¨‹é—´é€šä¿¡ï¼Œå…¶ä»–æ–¹å¼æ‰æ˜¯è¿œç¨‹è°ƒç”¨ã€‚è€Œ SSE=Server-Sent Eventsï¼Œè¯¥æ–¹æ³•æ˜¯æ—©èµ·ç‰ˆæœ¬çš„ã€‚

### **1. stdioï¼š**

å®˜æ–¹ä¾‹å­ https://github.com/modelcontextprotocol/python-sdk/blob/main/examples/clients/simple-chatbot/mcp_simple_chatbot/main.py ä¸­ï¼Œå°±ç”¨äº† stdio æ–¹å¼ã€‚æ‰€ä»¥å®ƒé‡Œé¢æ‰ä¼šæåˆ°å¯åŠ¨ server çš„ å‘½ä»¤è¡Œå‚æ•°ï¼š

<img width="1404" height="492" alt="image" src="https://github.com/user-attachments/assets/64cd7dde-7ee9-46ca-a625-d78c530ffe55" />

### **2. SSE:**

å°±æ˜¯å¼‚æ­¥è¯·æ±‚æ¨¡å¼ï¼Œclient å‘ server å‘é€è¯·æ±‚åï¼Œä¸èƒ½åŒæ­¥æ‹¿åˆ°ç»“æœã€‚ï¼ˆè¦åŒæ­¥ï¼Œåªèƒ½å¼„æˆä¼ªåŒæ­¥ï¼‰

```
// 1. é€šè¿‡ HTTP POST å‘é€è¯·æ±‚
const response = await fetch('/mcp/request', {
  method: 'POST',
  body: JSON.stringify({
    jsonrpc: "2.0",
    method: "tools/call",
    params: { name: "search" },
    id: 123  // å…³é”®ï¼šè¯·æ±‚ID
  })
});

// 1. å»ºç«‹ SSE è¿æ¥, ä»å¦ä¸€ä¸ªåœ°å€æ¥æ”¶å“åº”
const eventSource = new EventSource('/mcp/events');

eventSource.onmessage = function(event) { // å¤„ç†å›è°ƒ
  const mcpResponse = JSON.parse(event.data);
  if (mcpResponse.id === 123) {  // é€šè¿‡IDåŒ¹é…è¯·æ±‚
    console.log('æ”¶åˆ°å“åº”:', mcpResponse.result);
  }
};
```

### **3. streaming HTTPï¼š**

Streaming HTTP ï¼Œå…¶å®å°±æ˜¯çŸ­è¿æ¥çš„åŒæ­¥è¯·æ±‚æ¨¡å¼ã€‚ç»“æœæ˜¯æµå¼æ‹¿åˆ°çš„ã€‚

```
// å®¢æˆ·ç«¯å‘é€è¯·æ±‚
const response = await fetch('/mcp/tools/call', {
  method: 'POST',
  headers: {
    'Accept': 'text/plain', // æˆ– application/json-stream
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    jsonrpc: "2.0",
    method: "tools/call",
    params: { name: "search", arguments: { query: "hello" } },
    id: 123
  })
});

// æœåŠ¡å™¨è¿”å›æµå¼å“åº”: åŒæ­¥ç­‰å¾…ç»“æœ
const reader = response.body.getReader();
const decoder = new TextDecoder();

while (true) {
  const { done, value } = await reader.read();
  if (done) break;
  
  const chunk = decoder.decode(value);
  console.log('æ”¶åˆ°æ•°æ®å—:', chunk);
}
```

----

# ç¤ºä¾‹

mcp_server.pyï¼š

```
#!/usr/bin/env python3
"""
MCP Math Server - ä½¿ç”¨å®˜æ–¹ MCP SDK
å®‰è£…ä¾èµ–: pip install mcp
"""
import math
import asyncio
import sys
from datetime import datetime
from mcp.server import Server
from mcp.server.stdio import stdio_server
from mcp.types import Tool, TextContent

# åˆ›å»º MCP æœåŠ¡å™¨å®ä¾‹
app = Server("math-calculator")

@app.list_tools()
async def list_tools() -> list[Tool]:
    """æ³¨å†Œå¯ç”¨çš„å·¥å…·"""
    return [
        Tool(
            name="get_date_time",
            description="è¿”å›å½“å‰æ—¥æœŸæ—¶é—´ï¼Œæ ¼å¼ yy-mm-dd HH:MM:SS",
            inputSchema={
                "type": "object",
                "properties": {
                },
                "required": []
            }),
        Tool(
            name="transform_date_time",
            description="æŠŠæ—¥æœŸè½¬ä¸ºæ—¶é—´æˆ³ï¼Œæˆ–è€…æ—¶é—´æˆ³è½¬ä¸ºæ—¥æœŸ",
            inputSchema={
                "type": "object",
                "properties": {
                    "direction": {
                        "type": "string",
                        "description": "dt2u|u2dt, dt2u=datetime_to_unixtime, u2dt=unixtime_to_datetime",
                    },
                    "value": {
                        "type": "string",
                        "description": "éœ€è¦è½¬åŒ–çš„æ—¶é—´æˆ³æˆ–æ—¥æœŸæ—¶é—´. æ—¶é—´æˆ³éœ€è¦æ˜¯æ•´æ•°ï¼Œæ—¶é—´æ—¥æœŸæ ¼å¼éœ€è¦æ˜¯ yy-mm-dd HH:MM:SS",
                    }
                },
                "required": ["direction", "value"]
            }),
        Tool(
            name="calculate",
            description="è®¡ç®—æ•°å­¦è¡¨è¾¾å¼ï¼Œæ”¯æŒåŸºæœ¬è¿ç®—ã€å¹‚è¿ç®—ã€ä¸‰è§’å‡½æ•°ç­‰ã€‚å¯ä»¥ä½¿ç”¨ math æ¨¡å—çš„æ‰€æœ‰å‡½æ•°ã€‚",
            inputSchema={
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "è¦è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œä¾‹å¦‚: '2 + 3 * 4', 'math.sqrt(16)', 'math.sin(math.pi/2)'"
                    }
                },
                "required": ["expression"]
            })
    ]


@app.call_tool()
async def call_tool(name: str, arguments: dict):
    """å¤„ç†å·¥å…·è°ƒç”¨"""

    try:
        # ========== 1. get_date_time ==========
        if name == "get_date_time":
            now = datetime.now().strftime("%y-%m-%d %H:%M:%S")
            return [TextContent(type="text", text=f"å½“å‰æ—¶é—´: {now}")]

        # ========== 2. transform_date_time ==========
        elif name == "transform_date_time":
            direction = arguments.get("direction")
            value = arguments.get("value")

            if direction == "dt2u":  # datetime -> unix timestamp
                try:
                    dt = datetime.strptime(value, "%y-%m-%d %H:%M:%S")
                    timestamp = int(dt.timestamp())
                    return [TextContent(type="text", text=f"æ—¶é—´æˆ³: {timestamp}")]
                except Exception as e:
                    return [TextContent(type="text", text=f"æ—¥æœŸæ ¼å¼é”™è¯¯: {str(e)}")]

            elif direction == "u2dt":  # unix timestamp -> datetime
                try:
                    dt = datetime.fromtimestamp(float(value)).strftime("%y-%m-%d %H:%M:%S")
                    return [TextContent(type="text", text=f"æ—¥æœŸæ—¶é—´: {dt}")]
                except Exception as e:
                    return [TextContent(type="text", text=f"æ—¶é—´æˆ³é”™è¯¯: {str(e)}")]

            else:
                return [TextContent(type="text", text=f"æœªçŸ¥çš„ direction å‚æ•°: {direction}")]

        # ========== 3. calculate ==========
        elif name == "calculate":
            expression = arguments.get("expression", "")
            safe_dict = {
                "math": math,
                "__builtins__": {
                    "abs": abs,
                    "round": round,
                    "min": min,
                    "max": max,
                    "sum": sum,
                    "pow": pow,
                }
            }

            try:
                result = eval(expression, safe_dict, {})
                return [TextContent(type="text", text=f"è®¡ç®—ç»“æœ: {expression} = {result}")]
            except Exception as e:
                return [TextContent(type="text", text=f"è®¡ç®—é”™è¯¯: {str(e)}\nè¡¨è¾¾å¼: {expression}")]

        # ========== 4. æœªçŸ¥å·¥å…· ==========
        else:
            raise ValueError(f"Unknown tool: {name}")

    except Exception as e:
        return [TextContent(type="text", text=f"å·¥å…·è°ƒç”¨é”™è¯¯: {str(e)}")]

#@app.call_tool()
async def call_tool1(name: str, arguments: dict) -> list[TextContent]:
    """å¤„ç†å·¥å…·è°ƒç”¨"""
    if name != "calculate":
        raise ValueError(f"Unknown tool: {name}")

    expression = arguments.get("expression", "")

    try:
        # åˆ›å»ºå®‰å…¨çš„æ‰§è¡Œç¯å¢ƒ
        safe_dict = {
            "math": math,
            "__builtins__": {
                "abs": abs,
                "round": round,
                "min": min,
                "max": max,
                "sum": sum,
                "pow": pow,
            }
        }

        # æ‰§è¡Œè¡¨è¾¾å¼
        result = eval(expression, safe_dict, {})

        return [
            TextContent(
                type="text",
                text=f"è®¡ç®—ç»“æœ: {expression} = {result}"
            )
        ]

    except Exception as e:
        return [
            TextContent(
                type="text",
                text=f"è®¡ç®—é”™è¯¯: {str(e)}\nè¡¨è¾¾å¼: {expression}"
            )
        ]

async def main():
    """è¿è¡ŒæœåŠ¡å™¨"""
    # è¾“å‡ºå¯åŠ¨ä¿¡æ¯åˆ° stderrï¼ˆä¸å½±å“ stdio é€šä¿¡ï¼‰
    print("MCP Math Server starting...", file=sys.stderr, flush=True)

    try:
        async with stdio_server() as (read_stream, write_stream):
            print("MCP Math Server ready", file=sys.stderr, flush=True)
            await app.run(
                read_stream,
                write_stream,
                app.create_initialization_options()
            )
    except Exception as e:
        print(f"MCP Math Server error: {e}", file=sys.stderr, flush=True)
        raise

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("MCP Math Server stopped", file=sys.stderr, flush=True)
```

clientï¼š

```

#!/usr/bin/env python3
import asyncio
import json
import os
from typing import List, Dict, Optional
from openai import OpenAI
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

class AIAssistantWithMCP:
    """å¸¦ MCP å·¥å…·è°ƒç”¨èƒ½åŠ›çš„ AI åŠ©æ‰‹ï¼ˆæ”¯æŒä»»ä½• OpenAI å…¼å®¹ APIï¼‰"""

    def __init__(self, api_key: str, base_url: Optional[str] = None, model: str = "gpt-4-turbo"):
        """
        åˆå§‹åŒ– AI åŠ©æ‰‹

        Args:
            api_key: API å¯†é’¥
            base_url: API ç«¯ç‚¹ URL
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        self.conversation_history: List[Dict] = []
        self.mcp_session: Optional[ClientSession] = None
        self.available_tools: List[Dict] = []

    async def connect_mcp_server(self, server_script: str):
        """è¿æ¥åˆ° MCP æœåŠ¡å™¨"""
        import os

        # æ£€æŸ¥æœåŠ¡å™¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(server_script):
            raise FileNotFoundError(f"MCP æœåŠ¡å™¨æ–‡ä»¶ä¸å­˜åœ¨: {server_script}")

        server_params = StdioServerParameters(
            command="python3",
            args=[server_script],
        )

        print("ğŸ”Œ è¿æ¥åˆ° MCP æ•°å­¦æœåŠ¡å™¨...")

        try:
            # ä¿å­˜ context managers ä»¥ä¾¿åç»­æ¸…ç†
            self.stdio_context = stdio_client(server_params)
            self.read_stream, self.write_stream = await self.stdio_context.__aenter__()

            # åˆ›å»ºä¼šè¯
            self.session_context = ClientSession(self.read_stream, self.write_stream)
            self.mcp_session = await self.session_context.__aenter__()

            # åˆå§‹åŒ–ä¼šè¯
            await self.mcp_session.initialize()

            # è·å–å¯ç”¨å·¥å…·
            tools_list = await self.mcp_session.list_tools()

            # è½¬æ¢ä¸º OpenAI å·¥å…·æ ¼å¼
            for tool in tools_list.tools:
                self.available_tools.append({
                    "type": "function",
                    "function": {
                        "name": tool.name,
                        "description": tool.description,
                        "parameters": tool.inputSchema
                    }
                })

            print(f"âœ… å·²è¿æ¥ï¼å¯ç”¨å·¥å…·: {[t['function']['name'] for t in self.available_tools]}\n")

        except Exception as e:
            print(f"âŒ è¿æ¥ MCP æœåŠ¡å™¨å¤±è´¥: {e}")
            print("\nğŸ’¡ å¯èƒ½çš„åŸå› :")
            print(f"  1. æœåŠ¡å™¨æ–‡ä»¶ä¸å­˜åœ¨: {server_script}")
            print("  2. æœåŠ¡å™¨å¯åŠ¨å¤±è´¥ï¼ˆæ£€æŸ¥ mcp_math_server.py æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯ï¼‰")
            print("  3. Python ä¾èµ–ç¼ºå¤±ï¼ˆéœ€è¦ pip install mcpï¼‰")
            raise

    async def disconnect_mcp_server(self):
        """æ–­å¼€ MCP æœåŠ¡å™¨è¿æ¥"""
        try:
            if hasattr(self, 'session_context'):
                await self.session_context.__aexit__(None, None, None)
            if hasattr(self, 'stdio_context'):
                await self.stdio_context.__aexit__(None, None, None)
        except Exception as e:
            print(f"âš ï¸  æ–­å¼€è¿æ¥æ—¶å‡ºé”™: {e}")

    async def call_mcp_tool(self, tool_name: str, arguments: dict) -> str:
        """è°ƒç”¨ MCP å·¥å…·"""
        print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
        print(f"   å‚æ•°: {json.dumps(arguments, ensure_ascii=False)}")

        result = await self.mcp_session.call_tool(tool_name, arguments)

        # æå–æ–‡æœ¬ç»“æœ
        if result.content:
            result_text = result.content[0].text
            print(f"   ç»“æœ: {result_text}\n")
            return result_text

        return "å·¥å…·è°ƒç”¨å¤±è´¥"

    async def chat(self, user_message: str) -> str:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        # è°ƒç”¨ LLM API
        response = self.client.chat.completions.create(
            model=self.model,
            messages=self.conversation_history,
            tools=self.available_tools if self.available_tools else None, # æ³¨æ„è¿™é‡Œæ˜¯ function calling æ¥å®ç°
            tool_choice="auto" if self.available_tools else None,
        )

        # å¤„ç†å“åº”
        assistant_message = response.choices[0].message
        if assistant_message.tool_calls:
            return await self.handle_tool_calls(assistant_message)
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›æ–‡æœ¬
            response_text = assistant_message.content or ""

            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
            self.conversation_history.append({
                "role": "assistant",
                "content": response_text
            })

            return response_text

    async def handle_tool_calls(self, assistant_message):
        """
        å¯èƒ½ä¼šå¤šæ¬¡è°ƒç”¨å·¥å…·ï¼Œæ‰èƒ½è§£å†³ï¼Œæ‰€ä»¥åº”è¯¥æ˜¯é€’å½’çš„å½¢å¼ã€‚ç›´åˆ° LLM ä¸å†è°ƒç”¨ tool
        """
        # å¦‚æœ LLM æƒ³è¦ä½¿ç”¨å·¥å…·
        print ("   ---")
        if assistant_message.tool_calls:
            # æ·»åŠ åŠ©æ‰‹çš„å·¥å…·è°ƒç”¨è¯·æ±‚åˆ°å†å²
            self.conversation_history.append({
                "role": "assistant",
                "content": assistant_message.content,
                "tool_calls": [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }
                    }
                    for tc in assistant_message.tool_calls
                ]
            })

            # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
            for tool_call in assistant_message.tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)

                # è°ƒç”¨ MCP å·¥å…·
                tool_result = await self.call_mcp_tool(function_name, function_args)

                # æ·»åŠ å·¥å…·ç»“æœåˆ°å†å²
                self.conversation_history.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": function_name,
                    "content": tool_result
                })

            # è®© LLM æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
            final_response = self.client.chat.completions.create(
                model=self.model,
                messages=self.conversation_history,
                tools=self.available_tools,
            )

            final_message = final_response.choices[0].message
            final_text = final_message.content or ""
            still_need_func_call = 0
            if final_response.choices[0].message.tool_calls:
                still_need_func_call = 1
            if still_need_func_call and final_text:
                print ("   llm_out <<<", final_text, ">>>")

            if final_response.choices[0].message.tool_calls:
                return await self.handle_tool_calls(final_response.choices[0].message)

            # æ·»åŠ æœ€ç»ˆå›å¤åˆ°å†å²
            self.conversation_history.append({
                "role": "assistant",
                "content": final_text
            })

            #print (" func call finished ..")
            return final_text

    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…ç©º\n")

async def main():

    api_key = "sk-XXXXXX"
    base_url = "https://api.deepseek.com/v1"
    model = "deepseek-chat"

    assistant = AIAssistantWithMCP(api_key=api_key, base_url=base_url, model=model) # åˆ›å»º AI åŠ©æ‰‹
    await assistant.connect_mcp_server("mcp_math_server.py") # è¿æ¥ MCP æœåŠ¡å™¨
    print (" cmd: exit|clear")

    # äº¤äº’æ¨¡å¼
    while True:
        try:
            user_input = input("ç”¨æˆ·: ").strip()

            if not user_input:
                continue

            if user_input.lower() in ['quit', 'exit', 'q']:
                print("\nexit..")
                break

            if user_input.lower() == 'clear':
                assistant.clear_history()
                continue

            response = await assistant.chat(user_input)
            print(f"åŠ©æ‰‹: {response}")

        except KeyboardInterrupt:
            print("å†è§ï¼KeyboardInterrupt")
            break
        except Exception as e:
            print(f"é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            print()

if __name__ == "__main__":
    asyncio.run(main())

```

æ‰§è¡Œè®°å½•ï¼š

<img width="1332" height="1054" alt="image" src="https://github.com/user-attachments/assets/8ef9fef6-ae78-4b13-811d-606835f09375" />
